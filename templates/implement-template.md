# Implementation Log: {FEATURE_NAME}

**Status**: In Progress / Complete  
**Created**: {DATE}  
**Last Updated**: {DATE}  
**Feature Number**: {FEATURE_NUMBER}  
**Author**: {AUTHOR}

## Pattern Application Tracking

### Applied Patterns

- [Pattern ID 1]: [Status - Applied, Adapted, Challenging, etc.]
- [Pattern ID 2]: [Status - Applied, Adapted, Challenging, etc.]
- [Pattern ID 3]: [Status - Applied, Adapted, Challenging, etc.]

### Pattern Deviations

- [When and why did we deviate from expected patterns?]
- [What was learned from these deviations?]

### New Patterns Emerging

- [Did any new patterns emerge during implementation?]

## Implementation Progress

### Completed Tasks

[Reference tasks from tasks.md and mark completion]

### Current Status

[Overall progress toward feature completion]

### Blockers

[Any obstacles encountered]

### Changes from Plan

[How does current implementation differ from original plan?]

## Code Quality & Patterns

### Code Review Status

- [Peer review completed?]
- [Pattern compliance verified?]

### Testing Status

- [Unit tests written and passing?]
- [Integration tests completed?]
- [Pattern-specific validations passed?]

### Performance

- [Meet performance targets from plan?]
- [Any performance issues with pattern implementations?]

## Learning Evidence

### Time Tracking

- **Planned Time**: [From tasks.md]
- **Actual Time**: [Time actually spent]
- **Variance**: [Difference and reasons]

### Pattern Effectiveness Evidence

- [How effective were patterns in implementation?]
- [Where did patterns provide value?]
- [Where were patterns challenging to apply?]

### Quality Metrics

- Test coverage achieved
- Code complexity measures
- Defects found and fixed
- Review cycles required

### Unexpected Learnings

- What was easier than expected?
- What was harder than expected?
- What patterns worked better than anticipated?
- What patterns were more challenging than expected?

## Context Updates Needed

### Architecture Decisions

[Did this implementation reveal any architectural considerations?]

### Pattern Library Updates

- [Should any patterns be updated based on this experience?]
- [Are there new patterns to document?]
- [Any patterns that should be deprecated?]

### Team Capability Updates

[How has team capability changed after this implementation?]

## Next Steps for Learn Phase

### Key Outcomes to Analyze

1. [Primary outcome to examine]
2. [Secondary outcome to examine]
3. [Pattern effectiveness to evaluate]

### Data Collected

- Time metrics recorded
- Quality metrics captured  
- Pattern application evidence
- Deviation documentation

### Stakeholder Feedback Needed

[Who else might have insights for the learning phase?]

## Implementation Artifacts

### Code Files Created/Modified

[Link to specific files in the implementation]

### Configuration Changes

[Changes to settings, environments, etc.]

### Documentation Updates

[Updated internal docs, runbooks, etc.]

## Handoff to Learn Phase

**Ready for Learning Analysis**: [Yes/No]

**Key Questions for Learn Phase**:

1. How did pattern effectiveness match expectations?
2. What can we learn about our estimation process?
3. How should our patterns evolve based on this experience?

**Success Verification**:

- [ ] All planned functionality implemented
- [ ] All patterns applied as intended
- [ ] All learning evidence collected
- [ ] Next steps for adaptation identified
- [ ] Ready for Learn phase analysis
